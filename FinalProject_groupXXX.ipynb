{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COGS 118B - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Music Classification\n",
    "\n",
    "## Group members\n",
    "\n",
    "- Ana Maria Baboescu\n",
    "- Bradley Grace\n",
    "- Fatima Enriquez\n",
    "- Ngoc (Lucy) Giang\n",
    "- Stephanie Frianeza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract \n",
    "This section should be short and clearly stated. It should be a single paragraph <200 words.  It should summarize: \n",
    "- what your goal/problem is\n",
    "- what the data used represents \n",
    "- the solution/what you did\n",
    "- major results you came up with (mention how results are measured) \n",
    "\n",
    "__NB:__ this final project form is much more report-like than the proposal and the checkpoint. Think in terms of writing a paper with bits of code in the middle to make the plots/tables\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Background\n",
    "\n",
    "There has been ample amounts of research in the realm of music genre classification. This is in part because music is paramount in one’s culture and daily life. The music that one gets recommended on applications such as Spotfy/Pandora is classified using the different deep and machine learning approaches. In this manner, the greater “accuracy” for recommendations is best for the consumer because they will listen to music similar to what they already listen to <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1).\n",
    "Thus, the challenge for researchers is to understand what is the best model to use in order to classify the different genres. Convolutional Neural Network (CNN) and algorithms such as “Logistic Regression…[and] Random forest” have been utilized to extract the information from the Mel-frequencies. What Bahuleyan did at the University of Waterloo, Canada was take the data, sound waves and project them as spectrograms. In this manner, CNN can predict the genre of music. Subsequently, within their study, they depicted that there are two manners that can drive results in one manner over another. The transfer learning setting is essentially where the pre-trained weights are altered only in the manner of the feed-forward network. Additionally, the other setting is fine tuning the weights of the training process. Apart from these two settings, they also linked with the ideas of utilizing other machine learning applications. Yet, what was concluded was that between the two manners, there is no statistically significant difference in the genre classification of music. Subsequently, what they found as some of the best models for music genre classification problems was using the CNN approach or utilizing the XGBoost classifier <a name=\"cite_ref-2\"></a>[<sup>2</sup>](#cite_note-2). In this manner, the XGBoost is one of the preferred algorithms of machine learning because of its greater accuracy score over others such as random forest  <a name=\"cite_ref-3\"></a>[<sup>3</sup>](#cite_note-3). \n",
    "Furthermore, a similar approach has been conducted using the Free Music Archive dataset with different algorithms such as the CNN, Logistic Regression, and Artificial Neural Networks (ANN). Contrary to what most might believe, the ANN deep learning algorithm did not have the greatest score in terms of prediction accuracy. The CNN model, as aforementioned in the study above, actually proved to have the highest accuracy score of 88.54%. However, within their conclusion, the researchers determined that the CNN model is the best approach when working with spectrogram images; yet, ANN is “the best feature based classifier” <a name=\"cite_ref-1\"></a>[<sup>1</sup>](#cite_note-1). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem Statement\n",
    "\n",
    "Clearly describe the problem that you are solving. Avoid ambiguous words. The problem described should be well defined and should have at least one ML-relevant potential solution. Additionally, describe the problem thoroughly such that it is clear that the problem is quantifiable (the problem can be expressed in mathematical or logical terms), measurable (the problem can be measured by some metric and clearly observed), and replicable (the problem can be reproduced and occurs more than once)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "\n",
    "**FMA: A Dataset for Music Analysis**\n",
    "- Link: https://archive.ics.uci.edu/dataset/386/fma+a+dataset+for+music+analysis\n",
    "- Description: The dataset consists of 106,574 music tracks, each accompanied by additional features including song title, album, artist, genres, play counts, favorites, comments, description, biography, tags, and the audio of the track itself. It can be downloaded in four different size types: small, medium, large, full.\n",
    "- Observations: 106,574\n",
    "- Critical variables (how are they represented): There are a total of nine audio features (consisting of 518 attributes) for each of the 106,574 tracks. Each feature is represented as a real number.\n",
    "- Special handling/cleaning: No missing values, but it will need to be checked for duplicates, skewed distributions, and any other inconsistencies within the dataset. The dataset will also require processing to align with our objective of analyzing and classifying musical datasets of different genres.\n",
    "\n",
    "**Spotify Dataset**\n",
    "- Link: https://www.kaggle.com/datasets/sanjanchaudhari/spotify-dataset\n",
    "- Description: The dataset consists of 17,717 music tracks, accompanied by additional features including artist, album, album type, danceability, amount of energy, loudness, speechiness, acousticness, and instrumentalness.\n",
    "- Observations: 17,717\n",
    "- Critical variables (how are they represented): There are a total a nine features (artist, album, album type, danceability, amount of energy, loudness, speechiness, acousticness, and instrumentalness)\n",
    "- Special handling/cleaning: There are no values that are missing. The data will need to be checked for duplicates when being compared to other datasets, this will require a bit of cleaning and aligning of data\n",
    "\n",
    "\n",
    "**500 Greatest Songs of all Time**\n",
    "- Link: https://www.kaggle.com/datasets/omarhanyy/500-greatest-songs-of-all-time \n",
    "- Description: This dataset contains Rolling Stone’s definitive list of the 500 greatest songs of all time with attributes such as title, description, artist, etc.\n",
    "- Observations: 500\n",
    "- Critical variables (how are they represented): There are 9 critical features (title, song description, where it appears on, artist, writers, producer, released date, streak, song position)\n",
    "- Special handling/cleaning: This dataset is smaller in comparison to the other datasets and may need to be edited and cleaned when merged with our other datasets. This dataset will also be checked for duplicates and cleaned.\n",
    "\n",
    "\n",
    "**Prediction of Music Genre**\n",
    "- Link: https://www.kaggle.com/datasets/vicsuperman/prediction-of-music-genre/data \n",
    "- Description: Prediction of music genre provides a full list of genres included in the CSV are 'Electronic', 'Anime', 'Jazz', 'Alternative', 'Country', 'Rap', 'Blues', 'Rock', 'Classical', 'Hip-Hop'.\n",
    "- Observations: 41,700\n",
    "- Critical variables (how are they represented): There are 18 critical features (instance id, artist, track name, popularity, acousticness, danceability, duration in ms, energy, instrumentalness, music key, liveness, loudness, mode, speechiness, tempo, obtained date, valence, music genre). Majority of these features are tracked numerically with the exception of artist name, music key, and track name.\n",
    "- Special handling/cleaning: This dataset will be checked for duplications and cleaned. There will also be several features being cut such as valence and duration since it is not relevant to our focus. This dataset will also be edited in order to be able to merge with the other datasets.\n",
    "\n",
    "\n",
    "**Music Genre Classification**\n",
    "- Link: https://www.kaggle.com/datasets/harish24/music-genre-classification\n",
    "- Description: Music Genre Classification: Classification of different types of music genres by studying frequencies\n",
    "- Observations: 1,000\n",
    "- Critical variables (how are they represented): There are 10 critical features (music file, chroma stft, rmse, spectral centroid, spectral bandwidth, roll off, zero crossing rate, mfcc1, mfcc2, mfcc3). These features are tracked numerically by using frequencies.\n",
    "- Special handling/cleaning: This dataset will be checked for duplicates and cleaned. This specific dataset focuses on frequencies within the music and will be used to compare with the other datasets.\n",
    "\n",
    "\n",
    "**A Dataset For Music Analysis**\n",
    "- Link: https://github.com/mdeff/fma\n",
    "- Description: Music dataset used to evaluate several tasks in MIR, used for searching and organizing large music collections.\n",
    "- Observations: 8,000-106,574\n",
    "- Critical variables (how are they represented): There are 4 major variables (tracks, genres, features, echonest). \n",
    "- Special handling/cleaning: Parts of the dataset will have to be cut in order to accommodate the other datasets that are compiled.\n",
    "\n",
    "\n",
    "**GTZAN Genre Collection**\n",
    "- Link: https://www.kaggle.com/datasets/carlthome/gtzan-genre-collection\n",
    "- Description: This dataset was used in the paper “Musical genre classification of audio signals”, focusing on IEEE Transactions on Audio and Speech Processing 2002.\n",
    "- Observations: 1,000 (ten 100 files for each music genre)\n",
    "- Critical variables (how are they represented):  There are 10 file directories, each directory labeled for a specific genre of music (blues, classical, country, disco, hiphop, jazz, metal, pop, reggae, rock). In each directory there are 100 audio files for each specified genre. The dataset consists of 1,000 audio tracks each 30 seconds long. It contains 10 genres, each represented by 100 tracks. The tracks are all 22050 Hz monophonic 16-bit audio files in .au format.\n",
    "- Special handling/cleaning: This specific dataset will be analyzed by using the data we’ve collected from our other datasets.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proposed Solution\n",
    "\n",
    "In this section, clearly describe a solution to the problem. The solution should be applicable to the project domain and appropriate for the dataset(s) or input(s) given. Provide enough detail (e.g., algorithmic description and/or theoretical properties) to convince us that your solution is applicable. Make sure to describe how the solution will be tested.  \n",
    "\n",
    "If you know details already, describe how (e.g., library used, function calls) you plan to implement the solution in a way that is reproducible.\n",
    "\n",
    "If it is appropriate to the problem statement, describe a benchmark model<a name=\"sota\"></a>[<sup>[3]</sup>](#sotanote) against which your solution will be compared. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Metrics\n",
    "\n",
    "*Propose at least one evaluation metric that can be used to quantify the performance of both the benchmark model and the solution model. The evaluation metric(s) you propose should be appropriate given the context of the data, the problem statement, and the intended solution. Describe how the evaluation metric(s) are derived and provide an example of their mathematical representations (if applicable). Complex evaluation metrics should be clearly defined and quantifiable (can be expressed in mathematical or logical terms).*\n",
    "\n",
    "For our evaluation metrics we took from previous datasets to split into datasets, a training dataset and testing dataset, with which we used to both teach and test both our benchmark model and solution model. From the previous datasets we’ve used 80% of them as a training dataset, while the remaining 20% as testing dataset for the benchmark and solution model.\n",
    "\n",
    "\n",
    "We also tried to measure our models through the use of Gaussian Mixture Models clustering. The clusters were sorted through different variables used to form a distinction between the different types of genres of music. These variables will be loudness (amplitude), acousticness, instrumentalness, danceability of the music (tempo of the music), and speechiness in the music (the number of words in the song). The instrumentalness value represents the amount of vocals in the song, the closer it is to 1.0, the more instrumental the song is. The acousticness value describes how acoustic a song is where a score of 1.0 means the song is most likely to be an acoustic one.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "You may have done tons of work on this. Not all of it belongs here. \n",
    "\n",
    "Reports should have a __narrative__. Once you've looked through all your results over the quarter, decide on one main point and 2-4 secondary points you want us to understand. Include the detailed code and analysis results of those points only; you should spend more time/code/plots on your main point than the others.\n",
    "\n",
    "If you went down any blind alleys that you later decided to not pursue, please don't abuse the TAs time by throwing in 81 lines of code and 4 plots related to something you actually abandoned.  Consider deleting things that are not important to your narrative.  If its slightly relevant to the narrative or you just want us to know you tried something, you could keep it in by summarizing the result in this report in a sentence or two, moving the actual analysis to another file in your repo, and providing us a link to that file.\n",
    "\n",
    "### Main Point\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imported Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "import warnings\n",
    "\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 1 - Individual Datasets\n",
    "\n",
    "You will likely have different subsections as you go through your report. For instance you might start with an analysis of the dataset/problem and from there you might be able to draw out the kinds of algorithms that are / aren't appropriate to tackle the solution.  Or something else completely if this isn't the way your project works.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FMA Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/kn/4bc0njg93wsdfvw1806pg05m0000gn/T/ipykernel_17551/3530655725.py:7: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,11,13,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fma_features2 = pd.read_csv('datasets/fma/echonest.csv') # audio features provided by Echonest (now Spotify)\n",
      "/var/folders/kn/4bc0njg93wsdfvw1806pg05m0000gn/T/ipykernel_17551/3530655725.py:15: DtypeWarning: Columns (0,1,5,6,8,12,18,20,21,22,24,33,34,38,39,44,47,49) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fma_tracks1 = pd.read_csv('datasets/fma/tracks-1.csv')\n",
      "/var/folders/kn/4bc0njg93wsdfvw1806pg05m0000gn/T/ipykernel_17551/3530655725.py:24: DtypeWarning: Columns (0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,272,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344,345,346,347,348,349,350,351,352,353,354,355,356,357,358,359,360,361,362,363,364,365,366,367,368,369,370,371,372,373,374,375,376,377,378,379,380,381,382,383,384,385,386,387,388,389,390,391,392,393,394,395,396,397,398,399,400,401,402,403,404,405,406,407,408,409,410,411,412,413,414,415,416,417,418,419,420,421,422,423,424,425,426,427,428,429,430,431,432,433,434,435,436,437,438,439,440,441,442,443,444,445,446,447,448,449,450,451,452,453,454,455,456,457,458,459,460,461,462,463,464,465,466,467,468,469,470,471,472,473,474,475,476,477,478,479,480,481,482,483,484,485,486,487,488,489,490,491,492,493,494,495,496,497,498,499,500,501,502,503,504,505,506,507,508,509,510,511,512,513,514,515,516,517,518) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  fma_features1_1 = pd.read_csv('datasets/fma/features-1.csv')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title*\\*Artist</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Album Type</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Food*\\*AWOL</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>Food</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>Album</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electric Ave*\\*AWOL</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>Electric Ave</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>Album</td>\n",
       "      <td>0.6758939853</td>\n",
       "      <td>0.6344762684</td>\n",
       "      <td>0.1593100648</td>\n",
       "      <td>0.4166752327</td>\n",
       "      <td>0.0106280683</td>\n",
       "      <td>0.1776465712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This World*\\*AWOL</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>This World</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>Album</td>\n",
       "      <td>0.5286430621</td>\n",
       "      <td>0.8174611317</td>\n",
       "      <td>0.4618181276</td>\n",
       "      <td>0.3744077685</td>\n",
       "      <td>0.0018511032</td>\n",
       "      <td>0.1058799438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Freeway*\\*Kurt Vile</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>Album</td>\n",
       "      <td>0.7455658702</td>\n",
       "      <td>0.7014699916</td>\n",
       "      <td>0.1245953419</td>\n",
       "      <td>0.0435668989</td>\n",
       "      <td>0.0006967990</td>\n",
       "      <td>0.3731433124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiritual Level*\\*Nicky Cook</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>Spiritual Level</td>\n",
       "      <td>Niris</td>\n",
       "      <td>Album</td>\n",
       "      <td>0.6581786543</td>\n",
       "      <td>0.9245251615</td>\n",
       "      <td>0.0329852191</td>\n",
       "      <td>0.9516699648</td>\n",
       "      <td>0.9654270154</td>\n",
       "      <td>0.1154738842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Title*\\*Artist      Artist            Title  \\\n",
       "0                   Food*\\*AWOL        AWOL             Food   \n",
       "1           Electric Ave*\\*AWOL        AWOL     Electric Ave   \n",
       "2             This World*\\*AWOL        AWOL       This World   \n",
       "3           Freeway*\\*Kurt Vile   Kurt Vile          Freeway   \n",
       "4  Spiritual Level*\\*Nicky Cook  Nicky Cook  Spiritual Level   \n",
       "\n",
       "                  Album Album Type  Danceability        Energy   Speechiness  \\\n",
       "0  AWOL - A Way Of Life      Album           NaN           NaN           NaN   \n",
       "1  AWOL - A Way Of Life      Album  0.6758939853  0.6344762684  0.1593100648   \n",
       "2  AWOL - A Way Of Life      Album  0.5286430621  0.8174611317  0.4618181276   \n",
       "3     Constant Hitmaker      Album  0.7455658702  0.7014699916  0.1245953419   \n",
       "4                 Niris      Album  0.6581786543  0.9245251615  0.0329852191   \n",
       "\n",
       "   Acousticness Instrumentalness      Liveness  \n",
       "0           NaN              NaN           NaN  \n",
       "1  0.4166752327     0.0106280683  0.1776465712  \n",
       "2  0.3744077685     0.0018511032  0.1058799438  \n",
       "3  0.0435668989     0.0006967990  0.3731433124  \n",
       "4  0.9516699648     0.9654270154  0.1154738842  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://github.com/mdeff/fma\n",
    "\n",
    "# Import dataframes from CSV files\n",
    "#fma_tracks = pd.read_csv('datasets/fma/tracks.csv') # per track metadata such as ID, title, artist, genres, tags and play counts, for all 106,574 tracks.\n",
    "fma_genres = pd.read_csv('datasets/fma/genres.csv') # all 163 genres with name and parent\n",
    "#fma_features1 = pd.read_csv('datasets/fma/features.csv') # common features extracted with librosa\n",
    "fma_features2 = pd.read_csv('datasets/fma/echonest.csv') # audio features provided by Echonest (now Spotify)\n",
    "\n",
    "#fma_tracks.shape, \n",
    "fma_genres.shape, \n",
    "#fma_features1.shape, \n",
    "fma_features2.shape\n",
    "\n",
    "# Import the split dataset CSVs \n",
    "fma_tracks1 = pd.read_csv('datasets/fma/tracks-1.csv')\n",
    "fma_tracks2 = pd.read_csv('datasets/fma/tracks-2.csv')\n",
    "fma_tracks3 = pd.read_csv('datasets/fma/tracks-3.csv')\n",
    "fma_tracks4 = pd.read_csv('datasets/fma/tracks-4.csv')\n",
    "fma_tracks5 = pd.read_csv('datasets/fma/tracks-5.csv')\n",
    "fma_tracks6 = pd.read_csv('datasets/fma/tracks-6.csv')\n",
    "\n",
    "fma_tracks = pd.concat([fma_tracks1, fma_tracks2, fma_tracks3, fma_tracks4, fma_tracks5, fma_tracks6], ignore_index=True)\n",
    "\n",
    "fma_features1_1 = pd.read_csv('datasets/fma/features-1.csv')\n",
    "fma_features1_2 = pd.read_csv('datasets/fma/features-2.csv')\n",
    "fma_features1_3 = pd.read_csv('datasets/fma/features-3.csv')\n",
    "fma_features1_4 = pd.read_csv('datasets/fma/features-4.csv')\n",
    "fma_features1_5 = pd.read_csv('datasets/fma/features-5.csv')\n",
    "fma_features1_6 = pd.read_csv('datasets/fma/features-6.csv')\n",
    "fma_features1_7 = pd.read_csv('datasets/fma/features-7.csv')\n",
    "fma_features1_8 = pd.read_csv('datasets/fma/features-8.csv')\n",
    "fma_features1_9 = pd.read_csv('datasets/fma/features-9.csv')\n",
    "fma_features1_10 = pd.read_csv('datasets/fma/features-10.csv')\n",
    "fma_features1_11 = pd.read_csv('datasets/fma/features-11.csv')\n",
    "fma_features1_12 = pd.read_csv('datasets/fma/features-12.csv')\n",
    "fma_features1_13 = pd.read_csv('datasets/fma/features-13.csv')\n",
    "fma_features1_14 = pd.read_csv('datasets/fma/features-14.csv')\n",
    "fma_features1_15 = pd.read_csv('datasets/fma/features-15.csv')\n",
    "fma_features1_16 = pd.read_csv('datasets/fma/features-16.csv')\n",
    "fma_features1_17 = pd.read_csv('datasets/fma/features-17.csv')\n",
    "fma_features1_18 = pd.read_csv('datasets/fma/features-18.csv')\n",
    "fma_features1_19 = pd.read_csv('datasets/fma/features-19.csv')\n",
    "fma_features1_20 = pd.read_csv('datasets/fma/features-20.csv')\n",
    "fma_features1_21 = pd.read_csv('datasets/fma/features-21.csv')\n",
    "\n",
    "fma_features1 = pd.concat([fma_features1_1, fma_features1_2, fma_features1_3, fma_features1_4, fma_features1_5, fma_features1_6, fma_features1_7, fma_features1_8, fma_features1_9, fma_features1_10, fma_features1_11, fma_features1_12, fma_features1_13, fma_features1_14, fma_features1_15, fma_features1_16, fma_features1_17, fma_features1_18, fma_features1_19, fma_features1_20, fma_features1_21], ignore_index=True)\n",
    "\n",
    "# 12 = artist names\n",
    "fma_artist_names = fma_tracks['artist.12']\n",
    "fma_artist_names\n",
    "\n",
    "fma_track_titles = fma_tracks['track.19']\n",
    "fma_track_titles\n",
    "\n",
    "fma_album_titles = fma_tracks['album.10']\n",
    "fma_album_titles\n",
    "\n",
    "fma_album_types = fma_tracks['album.12']\n",
    "fma_album_types\n",
    "\n",
    "\n",
    "fma_danceability = fma_features2['echonest.1']\n",
    "fma_energy = fma_features2['echonest.2']\n",
    "#fma_loudness = fma_features2['echonest.']\n",
    "fma_speechiness = fma_features2['echonest.5']\n",
    "fma_acousticness = fma_features2['echonest']\n",
    "fma_instrumentalness = fma_features2['echonest.3']\n",
    "fma_liveness = fma_features2['echonest.4']\n",
    "\n",
    "\n",
    "# merge datasets. \n",
    "\n",
    "# use Title + Artist as the key.\n",
    "#df_top_500[\"Title,Artist\"] = df_top_500[\"Title\"] + \"*\\*\" + df_top_500[\"Artist\"]\n",
    "# Title*/*Artist is the key\n",
    "\n",
    "# loop through each row, add to new dataset if key not already present. \n",
    "fma_artist_names\n",
    "fma_track_titles\n",
    "fma_album_titles\n",
    "fma_album_types\n",
    "fma_danceability\n",
    "fma_energy\n",
    "fma_speechiness\n",
    "fma_acousticness\n",
    "fma_instrumentalness\n",
    "fma_liveness\n",
    "\n",
    "# truncate the first two rows (NaN, etc.)\n",
    "fma_artist_names = fma_artist_names[2:]\n",
    "fma_track_titles = fma_track_titles[2:]\n",
    "fma_album_titles = fma_album_titles[2:]\n",
    "fma_album_types = fma_album_types[2:]\n",
    "fma_danceability = fma_danceability[2:]\n",
    "fma_energy = fma_energy[2:]\n",
    "fma_speechiness = fma_speechiness[2:]\n",
    "fma_acousticness = fma_acousticness[2:]\n",
    "fma_instrumentalness = fma_instrumentalness[2:]\n",
    "fma_liveness = fma_liveness[2:]\n",
    "\n",
    "\n",
    "fma_artist_names = fma_artist_names.reset_index(drop=True)\n",
    "fma_track_titles = fma_track_titles.reset_index(drop=True)\n",
    "fma_album_titles = fma_album_titles.reset_index(drop=True)\n",
    "fma_album_types = fma_album_types.reset_index(drop=True)\n",
    "fma_danceability = fma_danceability.reset_index(drop=True)\n",
    "fma_energy = fma_energy.reset_index(drop=True)\n",
    "fma_speechiness = fma_speechiness.reset_index(drop=True)\n",
    "fma_acousticness = fma_acousticness.reset_index(drop=True)\n",
    "fma_instrumentalness = fma_instrumentalness.reset_index(drop=True)\n",
    "fma_liveness = fma_liveness.reset_index(drop=True)\n",
    "\n",
    "# create a dataframe that that combines all of the fma_ dataframes.\n",
    "fma = pd.DataFrame()\n",
    "fma = fma.assign(artist_names = fma_artist_names)\n",
    "fma = fma.assign(track_titles = fma_track_titles)\n",
    "fma = fma.assign(album_titles = fma_album_titles)\n",
    "fma = fma.assign(album_types = fma_album_types)\n",
    "fma = fma.assign(danceability = fma_danceability)\n",
    "fma = fma.assign(energy = fma_energy)\n",
    "fma = fma.assign(speechiness = fma_speechiness)\n",
    "fma = fma.assign(acousticness = fma_acousticness)\n",
    "fma = fma.assign(instrumentalness = fma_instrumentalness)\n",
    "fma = fma.assign(liveness = fma_liveness)\n",
    "\n",
    "# create a new column for the key (Title*/*Artist)\n",
    "fma.insert(0, 'Title*\\*Artist', fma_track_titles + \"*\\*\" + fma_artist_names)\n",
    "\n",
    "fma_columns = [\"Title*\\*Artist\", \"Artist\", \"Title\", \"Album\", \"Album Type\", \n",
    "               \"Danceability\", \"Energy\", \"Speechiness\", \"Acousticness\", \"Instrumentalness\", \"Liveness\"]\n",
    "\n",
    "# rename columns (except ignore Loudness as this dataset does not contain it)\n",
    "fma.columns = fma_columns\n",
    "\n",
    "fma.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speak about above dataset here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spotify Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title*\\*Artist       object\n",
      "Artist               object\n",
      "Title                object\n",
      "Album                object\n",
      "Album Type           object\n",
      "Danceability        float64\n",
      "Loudness            float64\n",
      "Speechiness         float64\n",
      "Acousticness        float64\n",
      "Instrumentalness    float64\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title*\\*Artist</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Album</th>\n",
       "      <th>Album Type</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gorillaz*\\*Feel Good Inc.</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>Feel Good Inc.</td>\n",
       "      <td>Demon Days</td>\n",
       "      <td>album</td>\n",
       "      <td>0.818</td>\n",
       "      <td>-6.679</td>\n",
       "      <td>0.1770</td>\n",
       "      <td>0.008360</td>\n",
       "      <td>0.002330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Gorillaz*\\*Rhinestone Eyes</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>Rhinestone Eyes</td>\n",
       "      <td>Plastic Beach</td>\n",
       "      <td>album</td>\n",
       "      <td>0.676</td>\n",
       "      <td>-5.815</td>\n",
       "      <td>0.0302</td>\n",
       "      <td>0.086900</td>\n",
       "      <td>0.000687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gorillaz*\\*New Gold (feat. Tame Impala and Boo...</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>New Gold (feat. Tame Impala and Bootie Brown)</td>\n",
       "      <td>New Gold (feat. Tame Impala and Bootie Brown)</td>\n",
       "      <td>single</td>\n",
       "      <td>0.695</td>\n",
       "      <td>-3.930</td>\n",
       "      <td>0.0522</td>\n",
       "      <td>0.042500</td>\n",
       "      <td>0.046900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gorillaz*\\*On Melancholy Hill</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>On Melancholy Hill</td>\n",
       "      <td>Plastic Beach</td>\n",
       "      <td>album</td>\n",
       "      <td>0.689</td>\n",
       "      <td>-5.810</td>\n",
       "      <td>0.0260</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.509000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gorillaz*\\*Clint Eastwood</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>Clint Eastwood</td>\n",
       "      <td>Gorillaz</td>\n",
       "      <td>album</td>\n",
       "      <td>0.663</td>\n",
       "      <td>-8.627</td>\n",
       "      <td>0.1710</td>\n",
       "      <td>0.025300</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Title*\\*Artist    Artist  \\\n",
       "0                          Gorillaz*\\*Feel Good Inc.  Gorillaz   \n",
       "1                         Gorillaz*\\*Rhinestone Eyes  Gorillaz   \n",
       "2  Gorillaz*\\*New Gold (feat. Tame Impala and Boo...  Gorillaz   \n",
       "3                      Gorillaz*\\*On Melancholy Hill  Gorillaz   \n",
       "4                          Gorillaz*\\*Clint Eastwood  Gorillaz   \n",
       "\n",
       "                                           Title  \\\n",
       "0                                 Feel Good Inc.   \n",
       "1                                Rhinestone Eyes   \n",
       "2  New Gold (feat. Tame Impala and Bootie Brown)   \n",
       "3                             On Melancholy Hill   \n",
       "4                                 Clint Eastwood   \n",
       "\n",
       "                                           Album Album Type  Danceability  \\\n",
       "0                                     Demon Days      album         0.818   \n",
       "1                                  Plastic Beach      album         0.676   \n",
       "2  New Gold (feat. Tame Impala and Bootie Brown)     single         0.695   \n",
       "3                                  Plastic Beach      album         0.689   \n",
       "4                                       Gorillaz      album         0.663   \n",
       "\n",
       "   Loudness  Speechiness  Acousticness  Instrumentalness  \n",
       "0    -6.679       0.1770      0.008360          0.002330  \n",
       "1    -5.815       0.0302      0.086900          0.000687  \n",
       "2    -3.930       0.0522      0.042500          0.046900  \n",
       "3    -5.810       0.0260      0.000015          0.509000  \n",
       "4    -8.627       0.1710      0.025300          0.000000  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "headers = [\"Artist\", \"Track\", \"Album\", \"Album_type\", \"Danceability\", \"Energy\", \"Loudness\",\"Speechiness\",\"Acousticness\",\"Instrumentalness\",\"Liveness\",\"Valence\",\"Tempo\",\"Duration_min\",\"Title\",\"Channel\",\"Views\",\"Likes\",\"Comments\",\"Licensed\",\"official_video\",\"Stream\",\"EnergyLiveness\",\"most_playedon\"]\n",
    "spotify_data = pd.read_csv('datasets/cleaned_dataset.csv', header = None, names = headers, skiprows=1,)\n",
    "spotify_data.head()\n",
    "\n",
    "selected_columns = [\"Artist\", \"Track\", \"Album\", \"Album_type\", \"Danceability\", \"Loudness\", \"Speechiness\", \"Acousticness\", \"Instrumentalness\"]\n",
    "spotify_data = spotify_data[selected_columns]\n",
    "\n",
    "spotify_data.rename(columns={'Album_type': 'Album Type'}, inplace=True)\n",
    "spotify_data.rename(columns={'Track': 'Title'}, inplace=True)\n",
    "\n",
    "spotify_data['Title*\\*Artist'] = spotify_data.apply(lambda row: row['Artist'] + '*\\*' + row['Title'], axis=1)\n",
    "\n",
    "cols = spotify_data.columns.tolist()\n",
    "cols = ['Title*\\*Artist'] + [col for col in cols if col != 'Title*\\*Artist']\n",
    "spotify_data = spotify_data[cols]\n",
    "\n",
    "#check what data types we have in the dataset\n",
    "print(spotify_data.dtypes)\n",
    "\n",
    "#check for any null values\n",
    "spotify_data[spotify_data.isnull().any(axis=1)]\n",
    "\n",
    "# export file\n",
    "# spotify_data.to_csv('spotify_data2.csv', index=False)\n",
    "\n",
    "# no duplicates\n",
    "spotify_data.drop_duplicates(\"Title*\\*Artist\") \n",
    "spotify_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speak about above dataset here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 500 Greatest Songs Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Description</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title*\\*Artist</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Like a Rolling Stone</td>\n",
       "      <td>\"I wrote it. I didn't fail. It was straight,\" ...</td>\n",
       "      <td>Bob Dylan</td>\n",
       "      <td>Like a Rolling Stone*\\*Bob Dylan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(I Can't Get No) Satisfaction'</td>\n",
       "      <td>\"It's the riff heard round the world,\" says St...</td>\n",
       "      <td>The Rolling Stones</td>\n",
       "      <td>(I Can't Get No) Satisfaction'*\\*The Rolling S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Imagine</td>\n",
       "      <td>John Lennon wrote \"Imagine,\" his greatest musi...</td>\n",
       "      <td>John Lennon</td>\n",
       "      <td>Imagine*\\*John Lennon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What's Going On</td>\n",
       "      <td>\"What's Going On\" is an exquisite plea for pea...</td>\n",
       "      <td>Marvin Gaye</td>\n",
       "      <td>What's Going On*\\*Marvin Gaye</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Respect</td>\n",
       "      <td>Otis Redding wrote \"Respect\" and recorded it f...</td>\n",
       "      <td>Aretha Franklin</td>\n",
       "      <td>Respect*\\*Aretha Franklin</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title  \\\n",
       "0            Like a Rolling Stone   \n",
       "1  (I Can't Get No) Satisfaction'   \n",
       "2                         Imagine   \n",
       "3                 What's Going On   \n",
       "4                         Respect   \n",
       "\n",
       "                                         Description              Artist  \\\n",
       "0  \"I wrote it. I didn't fail. It was straight,\" ...           Bob Dylan   \n",
       "1  \"It's the riff heard round the world,\" says St...  The Rolling Stones   \n",
       "2  John Lennon wrote \"Imagine,\" his greatest musi...         John Lennon   \n",
       "3  \"What's Going On\" is an exquisite plea for pea...         Marvin Gaye   \n",
       "4  Otis Redding wrote \"Respect\" and recorded it f...     Aretha Franklin   \n",
       "\n",
       "                                      Title*\\*Artist  \n",
       "0                   Like a Rolling Stone*\\*Bob Dylan  \n",
       "1  (I Can't Get No) Satisfaction'*\\*The Rolling S...  \n",
       "2                              Imagine*\\*John Lennon  \n",
       "3                      What's Going On*\\*Marvin Gaye  \n",
       "4                          Respect*\\*Aretha Franklin  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_top_500 = pd.read_csv('datasets/Top 500 Songs.csv',encoding='Latin 1')\n",
    "df_top_500 = df_top_500[[\"title\", \"description\", \"artist\"]] \n",
    "df_top_500.isnull().sum().sum() #no missing values (yay!) \n",
    "df_top_500 = df_top_500.rename(columns={\"artist\": \"Artist\", \"description\" : \"Description\", \"title\" : \"Title\"})\n",
    "df_top_500[\"Title*\\*Artist\"] = df_top_500[\"Title\"] + \"*\\*\" + df_top_500[\"Artist\"]\n",
    "df_top_500.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speak about above dataset here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction of Music Genre Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title*\\*Artist</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Röyksopp's Night Out*\\*Röyksopp</td>\n",
       "      <td>Röyksopp</td>\n",
       "      <td>Röyksopp's Night Out</td>\n",
       "      <td>0.00468</td>\n",
       "      <td>0.652</td>\n",
       "      <td>0.79200</td>\n",
       "      <td>0.115</td>\n",
       "      <td>-5.201</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0748</td>\n",
       "      <td>100.889</td>\n",
       "      <td>0.759</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shining Path*\\*Thievery Corporation</td>\n",
       "      <td>Thievery Corporation</td>\n",
       "      <td>The Shining Path</td>\n",
       "      <td>0.01270</td>\n",
       "      <td>0.622</td>\n",
       "      <td>0.95000</td>\n",
       "      <td>0.124</td>\n",
       "      <td>-7.043</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>115.00200000000001</td>\n",
       "      <td>0.531</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hurricane*\\*Dillon Francis</td>\n",
       "      <td>Dillon Francis</td>\n",
       "      <td>Hurricane</td>\n",
       "      <td>0.00306</td>\n",
       "      <td>0.620</td>\n",
       "      <td>0.01180</td>\n",
       "      <td>0.534</td>\n",
       "      <td>-4.617</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0345</td>\n",
       "      <td>127.994</td>\n",
       "      <td>0.333</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Nitro*\\*Dubloadz</td>\n",
       "      <td>Dubloadz</td>\n",
       "      <td>Nitro</td>\n",
       "      <td>0.02540</td>\n",
       "      <td>0.774</td>\n",
       "      <td>0.00253</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-4.498</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.2390</td>\n",
       "      <td>128.014</td>\n",
       "      <td>0.270</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Divide &amp; Conquer*\\*What So Not</td>\n",
       "      <td>What So Not</td>\n",
       "      <td>Divide &amp; Conquer</td>\n",
       "      <td>0.00465</td>\n",
       "      <td>0.638</td>\n",
       "      <td>0.90900</td>\n",
       "      <td>0.157</td>\n",
       "      <td>-6.266</td>\n",
       "      <td>Major</td>\n",
       "      <td>0.0413</td>\n",
       "      <td>145.036</td>\n",
       "      <td>0.323</td>\n",
       "      <td>Electronic</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            Title*\\*Artist                Artist  \\\n",
       "0          Röyksopp's Night Out*\\*Röyksopp              Röyksopp   \n",
       "1  The Shining Path*\\*Thievery Corporation  Thievery Corporation   \n",
       "2               Hurricane*\\*Dillon Francis        Dillon Francis   \n",
       "3                         Nitro*\\*Dubloadz              Dubloadz   \n",
       "4           Divide & Conquer*\\*What So Not           What So Not   \n",
       "\n",
       "                  Title  Acousticness  Danceability  Instrumentalness  \\\n",
       "0  Röyksopp's Night Out       0.00468         0.652           0.79200   \n",
       "1      The Shining Path       0.01270         0.622           0.95000   \n",
       "2             Hurricane       0.00306         0.620           0.01180   \n",
       "3                 Nitro       0.02540         0.774           0.00253   \n",
       "4      Divide & Conquer       0.00465         0.638           0.90900   \n",
       "\n",
       "   Liveness  Loudness   Mode  Speechiness               Tempo  Valence  \\\n",
       "0     0.115    -5.201  Minor       0.0748             100.889    0.759   \n",
       "1     0.124    -7.043  Minor       0.0300  115.00200000000001    0.531   \n",
       "2     0.534    -4.617  Major       0.0345             127.994    0.333   \n",
       "3     0.157    -4.498  Major       0.2390             128.014    0.270   \n",
       "4     0.157    -6.266  Major       0.0413             145.036    0.323   \n",
       "\n",
       "        Genre  \n",
       "0  Electronic  \n",
       "1  Electronic  \n",
       "2  Electronic  \n",
       "3  Electronic  \n",
       "4  Electronic  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_Music = pd.read_csv('datasets/music_genre.csv')\n",
    "\n",
    "#subset with wanted variables\n",
    "edited_pred_Music = pred_Music[[\"artist_name\", \"track_name\", \"acousticness\", \"danceability\", \n",
    "                                \"instrumentalness\", \"liveness\", \"loudness\", \"mode\", \"speechiness\", \n",
    "                                \"tempo\", \"valence\", \"music_genre\"]]\n",
    "\n",
    "#checked and got rid of duplicates\n",
    "edited_pred_Music = edited_pred_Music.drop_duplicates('track_name').copy()\n",
    "\n",
    "\n",
    "#changed name in columns artist_name and track_name and combined columns\n",
    "new_name_edited_pred_Music = edited_pred_Music.rename(columns={\n",
    "    \"artist_name\" : \"Artist\", \n",
    "    \"track_name\" : \"Title\",\n",
    "    \"music_genre\" : \"Genre\",\n",
    "    \"acousticness\" : \"Acousticness\",\n",
    "    \"danceability\" : \"Danceability\",\n",
    "    \"instrumentalness\" : \"Instrumentalness\",\n",
    "    \"liveness\" : \"Liveness\",\n",
    "    \"loudness\" : \"Loudness\",\n",
    "    \"mode\" : \"Mode\",\n",
    "    \"speechiness\" : \"Speechiness\",\n",
    "    \"tempo\" : \"Tempo\",\n",
    "    \"valence\" : \"Valence\"\n",
    "    })\n",
    "#new_name_edited_pred_Music[\"Title*\\*Artist\"] = new_name_edited_pred_Music[\"Title\"] + \"*\\*\" + new_name_edited_pred_Music[\"Artist\"]\n",
    "new_name_edited_pred_Music.insert(0, 'Title*\\*Artist', new_name_edited_pred_Music[\"Title\"] + \"*\\*\" + new_name_edited_pred_Music[\"Artist\"]) # replaced above line for index 0 insertion - Bradley\n",
    "new_name_edited_pred_Music.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Speak about above dataset here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 2 - Merged Dataset\n",
    "\n",
    "Another likely section is if you are doing any feature selection through cross-validation or hand-design/validation of features/transformations of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title*\\*Artist</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Album</th>\n",
       "      <th>Album Type</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Valence</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Instrumentalness</th>\n",
       "      <th>Description</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Electric Ave*\\*AWOL</td>\n",
       "      <td>Electric Ave</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>0.6344762684</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>Album</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.159310</td>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>Electric Ave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This World*\\*AWOL</td>\n",
       "      <td>This World</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>0.8174611317</td>\n",
       "      <td>AWOL - A Way Of Life</td>\n",
       "      <td>Album</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.105880</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.528643</td>\n",
       "      <td>0.461818</td>\n",
       "      <td>0.374408</td>\n",
       "      <td>0.001851</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>This World</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Freeway*\\*Kurt Vile</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>0.7014699916</td>\n",
       "      <td>Constant Hitmaker</td>\n",
       "      <td>Album</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.745566</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>Freeway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Spiritual Level*\\*Nicky Cook</td>\n",
       "      <td>Spiritual Level</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>0.9245251615</td>\n",
       "      <td>Niris</td>\n",
       "      <td>Album</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.115474</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.658179</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>0.951670</td>\n",
       "      <td>0.965427</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>Spiritual Level</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Where is your Love?*\\*Nicky Cook</td>\n",
       "      <td>Where is your Love?</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>0.5604099311</td>\n",
       "      <td>Niris</td>\n",
       "      <td>Album</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>0.096567</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513238</td>\n",
       "      <td>0.525519</td>\n",
       "      <td>0.452217</td>\n",
       "      <td>0.019443</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nicky Cook</td>\n",
       "      <td>Where is your Love?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Title*\\*Artist                Title      Artist  \\\n",
       "1               Electric Ave*\\*AWOL         Electric Ave        AWOL   \n",
       "2                 This World*\\*AWOL           This World        AWOL   \n",
       "3               Freeway*\\*Kurt Vile              Freeway   Kurt Vile   \n",
       "4      Spiritual Level*\\*Nicky Cook      Spiritual Level  Nicky Cook   \n",
       "5  Where is your Love?*\\*Nicky Cook  Where is your Love?  Nicky Cook   \n",
       "\n",
       "         Energy                 Album Album Type  Mode  Tempo  Valence  Genre  \\\n",
       "1  0.6344762684  AWOL - A Way Of Life      Album  -1.0    NaN      NaN   -1.0   \n",
       "2  0.8174611317  AWOL - A Way Of Life      Album  -1.0    NaN      NaN   -1.0   \n",
       "3  0.7014699916     Constant Hitmaker      Album  -1.0    NaN      NaN   -1.0   \n",
       "4  0.9245251615                 Niris      Album  -1.0    NaN      NaN   -1.0   \n",
       "5  0.5604099311                 Niris      Album  -1.0    NaN      NaN   -1.0   \n",
       "\n",
       "   Liveness  Loudness  Danceability  Speechiness  Acousticness  \\\n",
       "1  0.177647       NaN      0.675894     0.159310      0.416675   \n",
       "2  0.105880       NaN      0.528643     0.461818      0.374408   \n",
       "3  0.373143       NaN      0.745566     0.124595      0.043567   \n",
       "4  0.115474       NaN      0.658179     0.032985      0.951670   \n",
       "5  0.096567       NaN      0.513238     0.525519      0.452217   \n",
       "\n",
       "   Instrumentalness Description      Artist                Title  \n",
       "1          0.010628         NaN        AWOL         Electric Ave  \n",
       "2          0.001851         NaN        AWOL           This World  \n",
       "3          0.000697         NaN   Kurt Vile              Freeway  \n",
       "4          0.965427         NaN  Nicky Cook      Spiritual Level  \n",
       "5          0.019443         NaN  Nicky Cook  Where is your Love?  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merged the datasets together\n",
    "merged_dataset = pd.DataFrame()\n",
    "merged_dataset = pd.merge(fma, spotify_data, on=['Title*\\*Artist'], how='outer')\n",
    "\n",
    "# create a merged column from all _x and _y columns\n",
    "for column in merged_dataset.columns:\n",
    "    if column.endswith('_x'):\n",
    "        column_core = column[:-2]\n",
    "        column_y = column_core + '_y'\n",
    "        merged_dataset[column_core] = merged_dataset[column].fillna(merged_dataset[column_y])\n",
    "\n",
    "# drop all columns that end with _x or _y\n",
    "for col in merged_dataset.columns:\n",
    "    if col.endswith('_x') or col.endswith('_y'):\n",
    "        merged_dataset.drop(col, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# Do it again for the new_name_edited_pred_Music dataset\n",
    "\n",
    "merged_dataset = pd.merge(merged_dataset, new_name_edited_pred_Music, on='Title*\\*Artist', how='outer')\n",
    "\n",
    "# create a merged column from all _x and _y columns\n",
    "for column in merged_dataset.columns:\n",
    "    if column.endswith('_x'):\n",
    "        column_core = column[:-2]\n",
    "        column_y = column_core + '_y'\n",
    "        merged_dataset[column_core] = merged_dataset[column].fillna(merged_dataset[column_y])\n",
    "\n",
    "# drop all columns that end with _x or _y\n",
    "for col in merged_dataset.columns:\n",
    "    if col.endswith('_x') or col.endswith('_y'):\n",
    "        merged_dataset.drop(col, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# And again for the 500 Greatest Songs of All Time dataset\n",
    "\n",
    "merged_dataset = pd.merge(merged_dataset, df_top_500, on='Title*\\*Artist', how='outer')\n",
    "\n",
    "# create a merged column from all _x and _y columns\n",
    "for column in merged_dataset.columns:\n",
    "    if column.endswith('_x'):\n",
    "        column_core = column[:-2]\n",
    "        column_y = column_core + '_y'\n",
    "        merged_dataset[column_core] = merged_dataset[column].fillna(merged_dataset[column_y])\n",
    "\n",
    "# drop all columns that end with _x or _y\n",
    "for col in merged_dataset.columns:\n",
    "    if col.endswith('_x') or col.endswith('_y'):\n",
    "        merged_dataset.drop(col, axis=1, inplace=True)\n",
    "\n",
    "\n",
    "# print out the final expected row count\n",
    "final_expected_row_count = len(fma) + len(spotify_data) + len(df_top_500) + len(new_name_edited_pred_Music)  \n",
    "\n",
    "# Drop all rows that have NaN values for every feature\n",
    "key_features = ['Mode', 'Tempo', 'Valence', 'Genre', 'Liveness', 'Loudness', 'Danceability', 'Speechiness', 'Acousticness', 'Instrumentalness', 'Description']\n",
    "merged_dataset = merged_dataset.dropna(how='all', subset=key_features)\n",
    "\n",
    "\n",
    "# Move \"Artist\" and \"Title\" columns to the second index\n",
    "merged_dataset = merged_dataset.reindex(columns=['Title*\\*Artist', 'Title', 'Artist'] + merged_dataset.columns.tolist()[1:])\n",
    "\n",
    "# print out the final expected row count\n",
    "final_expected_row_count = len(fma) + len(spotify_data) + len(df_top_500) + len(new_name_edited_pred_Music)\n",
    "\n",
    "# Create a boolean mask where True indicates the presence of a '?'\n",
    "mask = merged_dataset.applymap(lambda x: x == '?')\n",
    "\n",
    "# Find columns with at least one '?'\n",
    "columns_with_question_mark = mask.any(axis=0)\n",
    "\n",
    "# Find rows with at least one '?'\n",
    "rows_with_question_mark = mask.any(axis=1)\n",
    "\n",
    "# convert symbol/string variables into float values\n",
    "merged_dataset['Mode'] = merged_dataset['Mode'].map({'Major': 1., 'Minor': 0.}).fillna(-1.)\n",
    "merged_dataset['Genre'] = merged_dataset['Genre'].map({'Alternative': 0., 'Anime': 1., 'Blues': 2., 'Classical': 3., 'Country': 4,\n",
    "                                                        'Electronic': 5., 'Hip-Hop': 6., 'Jazz': 7., 'Rap': 8., 'Rock': 9.}).fillna(-1.)\n",
    "merged_dataset['Tempo'] = merged_dataset['Tempo'].replace('?', np.nan)\n",
    "\n",
    "# rest of the variables to float values\n",
    "merged_dataset['Tempo'] = merged_dataset['Tempo'].astype(float)\n",
    "merged_dataset['Liveness'] = merged_dataset['Liveness'].astype(float)\n",
    "merged_dataset['Danceability'] = merged_dataset['Danceability'].astype(float)\n",
    "merged_dataset['Speechiness'] = merged_dataset['Speechiness'].astype(float)\n",
    "merged_dataset['Acousticness'] = merged_dataset['Acousticness'].astype(float)\n",
    "merged_dataset['Instrumentalness'] = merged_dataset['Instrumentalness'].astype(float)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "merged_dataset.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain above here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Subsection 3 - Descision Tree Classifier\n",
    "\n",
    "Probably you need to describe the base model and demonstrate its performance.  Maybe you include a learning curve to show whether you have enough data to do train/validate/test split or have to go to k-folds or LOOCV or ???\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3241428913929513\n",
      "Predicted Genre: [8.]\n",
      "The value for key '[8.]' is 'Rap'\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# split the merged dataset into two datasets, train and test (test dataset contains all the data where Genre is null)\n",
    "# train:\n",
    "merged_dataset_test = merged_dataset[merged_dataset['Genre'] == -1.]\n",
    "merged_dataset_test['Genre'].value_counts()\n",
    "# test:\n",
    "merged_dataset_train = merged_dataset[merged_dataset['Genre'] != -1.]\n",
    "merged_dataset_train['Genre'].value_counts()\n",
    "\n",
    "\n",
    "# dataset used for Tree Classifier (train + test)\n",
    "lessNaNs = merged_dataset_train.dropna(subset=['Loudness', 'Danceability','Speechiness', 'Acousticness', 'Instrumentalness'])\n",
    "\n",
    "# dataset where user may pick a song to find out its Genre (used to further test)\n",
    "test_lessNaNs = merged_dataset_test.dropna(subset=['Loudness', 'Danceability','Speechiness', 'Acousticness', 'Instrumentalness'])\n",
    "\n",
    "\n",
    "# Extract features and target variable\n",
    "X = lessNaNs[[ 'Loudness', 'Danceability', 'Speechiness', 'Acousticness', 'Instrumentalness']]\n",
    "y = lessNaNs['Genre']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Initialize the decision tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Predict the genre of songs in the test set\n",
    "predictions = clf.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Now we used this trained classifier to predict the genre of new songs by providing the respective features\n",
    "\n",
    "variables_of_interest = [ 'Loudness', 'Danceability', 'Speechiness', 'Acousticness', 'Instrumentalness']\n",
    "\n",
    "# Allow users to input the index for the song that they want to know the genre of\n",
    "row_index = input(\"Enter the row you want: \")\n",
    "row_index = int(row_index)\n",
    "# test song index: 106974 --> Pepas (Rap)\n",
    "\n",
    "selected_values = test_lessNaNs.loc[row_index, variables_of_interest]\n",
    "new_song_features = [selected_values.tolist()]\n",
    "  \n",
    "predicted_genre = clf.predict(new_song_features)\n",
    "\n",
    "print(\"Predicted Genre:\", predicted_genre)\n",
    "\n",
    "reverse_mapping = {0.0: 'Alternative', 1.0: 'Anime', 2.0: 'Blues', 3.0: 'Classical', 4.0: 'Country', 5.0: 'Electronic', 6.0: 'Hip-Hop', 7.0: 'Jazz', 8.0: 'Rap', 9.0: 'Rock', -1.0: 'Unknown'}\n",
    "test_lessNaNs['Genre'] = test_lessNaNs['Genre'].map(reverse_mapping)\n",
    "\n",
    "\n",
    "# Iterate over the dictionary keys\n",
    "for key in reverse_mapping:\n",
    "    # Check if the current key matches the user input key\n",
    "    if key == predicted_genre:\n",
    "        # Assign the value associated with the matching key to the variable\n",
    "        value_for_key = reverse_mapping[key]\n",
    "        # Break the loop since we found the appropriate value\n",
    "        break\n",
    "\n",
    "# Check if the value for the user input key was found\n",
    "if value_for_key is not None:\n",
    "    print(f\"The value for key '{predicted_genre}' is '{value_for_key}'\")\n",
    "else:\n",
    "    print(f\"The key '{predicted_genre}' does not exist in the dictionary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain above here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Subsection 4 - GMM Clustering\n",
    "\n",
    "Perhaps some exploration of the model selection (hyper-parameters) or algorithm selection task. Validation curves, plots showing the variability of perfromance across folds of the cross-validation, etc. If you're doing one, the outcome of the null hypothesis test or parsimony principle check to show how you are selecting the best model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsection 5 \n",
    "\n",
    "Maybe you do model selection again, but using a different kind of metric than before?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Interpreting the result\n",
    "\n",
    "**OK, you've given us quite a bit of tech informaiton above, now its time to tell us what to pay attention to in all that.  Think clearly about your results, decide on one main point and 2-4 secondary points you want us to understand. Highlight HOW your results support those points.  You probably want 2-5 sentences per point.**\n",
    "\n",
    "Our direct results show that for every row index we feed into our model, our classification tool outputs about a 33% accuracy. However, based on each of our team members’ personal criteria for classifying music genres, we found our model to have a rough ~60-70% accuracy level. Majority of the time, when we inputted a row index for a song we were all familiar with, the tree classifier outputted the “correct” genre (number). \n",
    "- A reason for our direct results may be that about 20% of our data is for testing while 80% was used for training. We can observe this at the beginning of our team’s ‘Music Categorization’ section where we assigned the variable ‘test_size’ = 0.2. Ideally we would have liked our testing dataset to be about 30% of our entire data to ensure better accuracy.\n",
    "- In addition, this level of accuracy may have been determined by the lack of variables our team used for our datasets (loudness, danceability, speechiness, acousticness, and instrumentalness) which did not give our classification model much to learn from. Potentially, for the future, finding more datasets that match our data criteria but also have additional variables we can use as music characteristics could boost our classification tool’s accuracy.\n",
    "\n",
    "\n",
    "### Limitations\n",
    "\n",
    "**Are there any problems with the work?  For instance would more data change the nature of the problem? Would it be good to explore more hyperparams than you had time for?**\n",
    "\n",
    "One of the main limitations we faced in this project was time. With this constraint we were limited in how far we could explore to acquire necessary data for our project. For example, we needed to use the datasets created by others rather than our own, which would sometimes lead to us not having some of the variables we wanted. Using data collected by outside sources (with many independent variables that were not used by our own team) resulted in our data having many null values, which was not helpful during the data wrangling process. With time as a limiting factor we were also unable to generate more clustering visualizations, in addition to our gaussian mixture model. As we were working on our GMM we ran into multiple compilation errors that hindered our ability to perfect our model, and also prevented us from exploring other visual analyses such as PCA, K-Means, etc. Furthermore, from an outsider’s perspective, some of the songs in our merged dataset are characterized as being a part of 2 or more genre categories. However, since our merged dataset limits each song to only belonging to 1 genre, this may have caused inaccuracies in our model.\n",
    "\n",
    "### Ethics & Privacy\n",
    "\n",
    "In developing a music classification system, our team acknowledges the importance of addressing potential ethical concerns and privacy implications that may arise. We recognize the need to prioritize ethical considerations and safeguard user privacy throughout the development phases especially with our use of a dataset that relies on user behavior information. \n",
    "Ethical Considerations:\n",
    "Bias: One of the primary ethical concerns in ML-based recommendation systems is the potential for bias in the recommendations. Our team will strive to ensure that the system does not inadvertently reinforce or perpetuate biases related to race, gender, age, or other sensitive attributes. We will implement fairness-aware algorithms and regularly assess the system's performance across diverse user groups to mitigate any biases that may arise.\n",
    "Transparency: Users should have visibility into how the classification system operates and why certain classifications are made. We will prioritize transparency by documenting the algorithmic processes, providing explanations for recommendations, and enabling users to understand and control their preferences and data usage. \n",
    "User Consent: Respecting user autonomy and privacy preferences is paramount. We will incorporate mechanisms for obtaining informed consent from users regarding data collection, processing, and usage for personalized recommendations. \n",
    "\n",
    "\n",
    "Privacy Considerations: \n",
    "Data Security: Protecting sensitive user data is of utmost importance to us. We will adopt a data minimization approach, collecting only necessary data required for our classification system in order to safeguard user data throughout its lifecycle.\n",
    "Anonymity: Wherever possible, we will anonymize or de-identify user data to protect individual privacy while still enabling effective system performance. This includes using techniques such as differential privacy to prevent the re-identification of individuals from aggregated data.\n",
    "\n",
    "\n",
    "Our team recognizes that despite proactive measures, unforeseen ethical dilemmas and privacy challenges may emerge once the system is in production. To address these issues, we will establish continuous monitoring, conduct regular ethical audits using tools like Deon (https://deon.drivendata.org), and remain responsive to emerging ethical guidelines and regulatory frameworks.\n",
    "\n",
    "### Conclusion\n",
    "\n",
    "**Reiterate your main point and in just a few sentences tell us how your results support it. Mention how this work would fit in the background/context of other work in this field if you can. Suggest directions for future work if you want to.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Footnotes\n",
    "\n",
    "1. <a name=\"cite_note-1\"></a> [^](#cite_ref-1) Chillar, Snigdha et al. (May 2019) Music Genre Classification using Machine Learning Algorithms: A comparison. *International Research Journal of Engineering and Technology (IRJET)*. https://d1wqtxts1xzle7.cloudfront.net/59934287/IRJET-V6I517420190704-120568-1u4iafr-libre.pdf?1562308085=&response-content-disposition=inline%3B+filename%3DIRJET_Music_Genre_Classification_using_M.pdf&Expires=1708407619&Signature=WRJ6JnCTvv8fyWmo~A-SzVQ2DRT77pSZFX8tmlz7YCCB7J5ZMkrJpugkiwlJT7DoaCR-d2jI6IfGjgYXI9-EsJlVANQ~gJY04gUz9H4zkZG-HiyimSeXcAkK58Rqp06qgvlu-yx5zcM1wNxrnhgASBQEvVBkhyQMxETbkgtLYzw40gKVZFeioo0Qjj7aqC-YDzGwlzlnXhNss4xlBsBj7PdyTFgGu2cM8ky8g3XsqA1yIIuiO4cr0SEcCJU8orRATVTpB388Nud0GvNiGOz6DAhpoCBLEqrsYxFHk2jOut7x1TPs91ECXgG1SwjPE03vlYoeAMEkdV5pasBm1yZDeQ__&Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA\n",
    "\n",
    "2. <a name=\"cite_note-2\"></a> [^](#cite_ref-2) Bahuleyan, Hareesh( 3 April 2018) Music Genre Classification using Machine Learning Techniques. Cornell University. https://doi.org/10.48550/arXiv.1804.01149\n",
    "\n",
    "3. <a name=\"cite_note-3\"></a> [^](#cite_ref-3) Wohlwend, Brandon (23 July 2023) Decision Tree, Random Forest, and XGBoost: An Exploration into the Heart of Machine Learning. Medium. https://medium.com/@brandon93.w/decision-tree-random-forest-and-xgboost-an-exploration-into-the-heart-of-machine-learning-90dc212f4948#:~:text=Random%20Forests%20build%20on%20this,that%20often%20outperforms%20many%20others.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
